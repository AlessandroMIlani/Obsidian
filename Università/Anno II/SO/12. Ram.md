## RAM
- **Risorsa disponibile ai processi**
- **Accesso della cpu, alla ram attraverso gli indirizzi che produce**

CPU -> la vediamo come generatore di un flusso d'indirizzi (dati / flussi)
Ram -> array d'indirizzi

- Quando la cpu esegue un programma, cerca gli indirizzi di ram indicati nel programma, ma ciò può impedire la rilocabilità del codice

- Adesso, la maggior parte dei linguaggi permette la rilocabilità del codice (in java, non ci siamo mai preoccupati d'idicare le celle di ram)
	- Ci pensa il compilatore: 
	- Programma sorgente (indirizzi simbolici) -> compilaotre -> indirtizzi assoluti

```mermaid 
	flowchart TD
Prog.sorgente --> compilatore
compilatore --> indirizzi-assoluti
compilatore --> c(moulo oggetto \n ind. riallocabili base + 100byte)
compilatore --> linker
modulo.oggetto --> linker
linker --> d(modulto rilocabile)
d --> loader
e(lib. di sistema) --> loader
loader --> f(modello eseguibile)
````
- Gli indirizzi assoluti non si usano quasi più
- Creo dei moduli oggetto, i quali sfruttano indirizzi rilocabili
	- Spesso un programma è composto da più file più file oggetto, quindi il linker li unisce
	- il loader unice le lib. di sistema necessarie e crea il modello eseguibile.
		-  Quindi, la cpu eseguendo il programma cerca un inidirizzo logico (nome persona in rubrica) che viene collegato ad un indirizzo fisico in Ram (numero di telefono)

- Indirizzi generati della CPU -> Spazio degli Indirizzi Logici del processo
	-	<==> Binding tra i 2 spazi degli indirizzi
- Indirizzi in Ram -> spazio degli indirizzi fisici del processo

### MMU
**Memory Manag. Unit**

```mermaid 
	flowchart LR
a(CPU \n Ind. logico) --> b(+)
subgraph MMU
c(registro di rilocazione) --> b
end
b --> d(indirizzo fisico)
````

**Linking**
Permette la composizione di più moduli che compongono lo stesso programma
(es. Modulo1 con funzione -> modulo2 con dichiarate le variabili della funzione)

**Loading**
 È il software di sistema che carica il file eseguibile generato dal linker nella memoria principale
 
Sono detti:
- statici, se eseguiti prima dell'esecuzione (quando creo il mio "a.out")
	- Si caricano tutte le librerie (COMPLETE) in memoria 
```mermaid 
	flowchart LR
a(oggetto 1) --> linker
b(oggetto 2) --> linker
c(oggetto 3) --> linker
linker --> d(modello eseguibile)
````

- Dinamici, se avvengono durante l'esecuzione (ho il mio a.out, ma l'aggancio con una eventuale funzione stampa, viene creato al primo richiamo della funzione)

##### Librerie dinamiche
- Può venir modificata senza chiede ai programmi invocanti di venire ricompilati 

#### Allocazione della ram ai processi
Diversi approcci
1. Allocazione contigua
2. paginazione
3. segmentazione

##### Allocazione Contigua
Una parte viene subito assegnata al SO, noi ci occuperemo del resto disponibile ai processi utente.

![[Pasted image 20211113161040.png]]
- Mando in esecuzione 2 programmi (P1 e P2) e successivamente termina P1#
- ![[Pasted image 20211113161149.png]]
- Se mando P3 in running quale spazio occupa?
	- Se va ad occupare lo spazio di P1, si crea un **frammento interno** tra lui e P2, ovvero un frammento troppo piccolo per contenere un processo e, quindi, viene inglobato dalla memoria circostante
	- La parte libera sottostante P2 fiene detto **Frammento esterno** in quanto abbastanza grande da essere utlizzato da altri processi.

**Tipo di allocazione**
1. Best Fit
2. First Fit
3. Worst Fit

*Esempio:*
Processo richiede 10 "unità" di ram e ci sono liberi blocchi da 15,11,25 e 5
1. Best Fit --> sceglierà quello più piccolo in cui entra 10 (11), e il frammento interno che si crea, viene inglobato da p;
2. Worst Fit --> si sceglie il frammento più grande (25), supponendo che nello spazio rimanente possa entrare un altro processo
3. First Fit --> Il primo in grado di contenere il processo (15), può generare un frammento interno o esterno in base alla parte restante

**Memoria inutilizzabile**
A forza di frammenti interni, la RAM è "spezzettata"
- La tecnica First Fit fa perdere circa il 50%, ogni N blocchi perdo N/2, quindi perdo 1/3 della ram.
- Best first è simile al First
- Worst è la peggiore, a lungo andare crea frammenti inutilizzabili

![[Pasted image 20211113162214.png]]

**Come ottengo la rilocabilità?**
 Invece di far partire la memoria da 0, iniziamo a u numero differente (0-max --> 100-100+max)
 Per la CPU gli spazi sono sempre[0,max]
 ![[Pasted image 20211113162610.png]]
 In questo modo viene guadagnata la rilocabilità. Perché?
 *Swapping/Schedulind* medio termine: ![[Pasted image 20211113162934.png]]
 - C è un processo in ready e supponiamo occupi da 100 a 150
 - C va in Ram grazie allo scheduler, ma cambia indirizzo: la sua partizione è [350,400]

Tale approccio ha 2 caratteristiche:
1. Vincolo di continuità -> spazio indirizzi fisici di ciascun processo è contiguo
2. Assunzione implicita -> caricamento completo del processo

##### Paginazione
Non sfrutta la continuità:
- Spazio ind. fisici di P= $I_A \cup I_B \cup I_C$

Immaginiamo la ram divisa in porzioni dette **Frame**
Mem. logica del processore divisa in parti di pari dimensione dette **pagine**
- un indirizzo logico è una coppia <p,o> (p -> pagina | o -> offset)

![[Pasted image 20211113165748.png]]

La paginazione permette la rilocabilità? SI

Supponiamo uno spazio grande $2^m$ e pagine grandi $2^n$, facendo $\frac{2^m}{2^n}$ ottengo il numero di pagine necessarie al processo
- (m-n)bit per scrivere la componente p dell'indirizzo logico 
- per l'offset mi serve invece il dato n

**Approfondimento swapping:** *il S.O. deve caricare il processo:*

```C
if(#frame liberi >= pagine p){
	foreach(pagine di P){
		<<identifica frame libero>>
		<<crea entry nella tabella delle pagine p>> ||
		<<causa la copiatura della pagina nel fram>>
		<<aggiorna le informazioni sui frame liberi>>
	else...
		TO BE CONTINUED..
	}
}
```

![[Pasted image 20211113170452.png]]

Alcune architetture implementano della memoria Cache / TLB che memorizza parte della tabella dele pagine.
Cerco nel frammenot salvato se ho il mio inirizzo logico, se non lo trovo, accedo alla ram e cerco li

| p   | f   |
| --- | --- |
| p1  | f1  |
| p2  | f2  |
| p3  | f3  |
| pn  | fn  |


**ES**
- SO: Paginazione + TLB
- Hit Ratio (percentuale di successo): 92% 
	- richiede 1 tempo di accesso al TLB + 1 tempo di accesso alla RAM 
- TLB Miss: 8% (= 100% - Hit Ratio)
	- richiede 2 volte il tempo di accesso alla ram 

Tempo accesso al TLB = 20
Tempo accesso alla Ram = 100

Tempo medio di accesso alle pagine? = $(20+100)*0.92+200*0.08=126,4$


###### Condivisione di Pagine
Spesso i processi sfruttano delle librerie caircate con linking/loading dinamici.
Ipotizioamo che la funzione stanf sia caricata in 1 pagina della sua libreria.
- I processi che volgio utilizzare la funzione possono prendere la sua pagina ed agganciarla alla loro rista delle pagine
- Se anche P1 vuole accedere a quella pagina, al posto di copiare la pagina, la si può linkare nella loro tabella delle pagine
	- in questo modo, evito di moltiplicare la pagina per ogni programma che ne necessita

**Posso condividere pagine in scrittura?**
Si, tramite la memoria condivisa.
Per esempio un buffer, può avere una pagina presente sia in P che P1 ocsì da permettre uno scambio di dati.

| pagine | modalità di accesso |
| ------ | ------------------- |
| P      | R                   |
| P1     | R/W                 |
| P2     | R/W                 |
| ..     | ...                 |
| Pn     | W                   | 

###### Implementazione tabella delle pagine
*Problema:*
Può essere molto grande, e deve essere contigua.

**Paginazione Multi-Livello, albero a 2 livelli**
Al posto di un array, utilizzo un albero
```mermaid 
	flowchart LR
a(tabella delle pagine esterna) --> b
a --> c(porzione tab. pagine)
b(porzione tab. pagine) --> d
b --> e
c --> f

````
- I dati/funzioni efettivi, sono nelle foglie
- Devo modificare gli indirizzi logici.
	- devo suare delle triple <p1,p2,o>
		- p1 -> accesso tab. pag. esterna
		- p2 -> porzione tabella delle pagine
		- o -> offset
			- poi tradotto il tutto nel ind. fisico: <f,o>

---
- Hash Table
- Posso invertire il punto di vista.
	- sempre usato il p.v. del processo: si pate dallo spazio ind. logici
	- Passo al punto di vista della RAM
	- Tabella che ha tanti elementi quanti i frame: <pid,p,o>
		- p -> pagina, o -> offset, pid -> identifica il processo

**Tabella delle pagine inversa/invertita**

| indice | pid  | p   |
| ------ | ---- | --- |
| 0      | 3001 | 2   | 
| .      | .    | .   |
| ..     | ..   | ..  |
| ...    | ...  | ... |
| n      | nn   | nnn |

- controllo sequenziale
	- prima cerco il pid, poi che la pagina corrisponda ed infine l'offset 


**recuperare grafico fatto bene da video o Miriam**
CPU --> <pid,p,o> : indirizzo logico

Pid e p permettono di recueprare l'indice per l'indirizzo finisico: <i,o>

#### Segmentazione
- ogni processo ha assegnato dei segmenti sparsi nella ram
- non vede la memoria divisa in frame uguali
- In ogni segmento ho dati omogenei (solo dati, solo codice ...)

*sfruttao sia caratteristiche delle partizioni continue che della paginazione.*
- ogni segmento ha u indirizzo baase
- Ho una tabella dei segmenti

<s,o> s = segmento, o = offset

**da ind. logico a fisico**
Logico: <s,o>
s mi indica un accesso diretto alla tabella dei segmenti (è un po' come un indice)
- all'interno della tabella trovo l'indirizzo base del segmento e la sua dimensione limite 
	

| base | limite |
| ---- | ------ |
| i = 40   | 1000   |	
	
- controllo che l'offset sia $\leq$ del limite
	- se la risposta è si, accesso legale alla memoria e compongo l'ind. fisico:
		- ricopio l'offset ed aggiungo l'indice che è la base del segmento
		- <o,i>


###### Segmentazione paginata
- ogni segmento è un multiplo di un valore base
- è utilizzada attiavemente da molte architetture

cpu -ind.logic-> Unità di segmentazione -ind.lineare->unità di paginazione --> ram
- i segmenti possono essere locali o globali ( librerie)
- ind. logico = <s, g/l,o> -trasformo in indirizzo per alberi a 2 livelli-> <p1,p2,o> -> ind. fisico


[[13. Ram p2]]